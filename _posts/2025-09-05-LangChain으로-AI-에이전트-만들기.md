---
title: "LangChainìœ¼ë¡œ AI ì—ì´ì „íŠ¸ ë§Œë“¤ê¸°: ì‹¤ìŠµ"
date: 2025-09-05 19:30:00 +0900
categories: [AI, LangChain, ì—ì´ì „íŠ¸]
tags: [LangChain, AIì—ì´ì „íŠ¸, ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜, ìë™í™”]
---

# LangChainìœ¼ë¡œ AI ì—ì´ì „íŠ¸ ë§Œë“¤ê¸°: ì™„ì „ ì‹¤ìŠµ

LangChainì€ AI ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ ê°•ë ¥í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ì´ ê¸€ì—ì„œëŠ” LangChainì„ í™œìš©í•˜ì—¬ ì§€ëŠ¥ì ì¸ AI ì—ì´ì „íŠ¸ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.

## ğŸ¤” LangChainì´ë€?

**LangChain**ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ ì˜¤í”ˆì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

### í•µì‹¬ íŠ¹ì§•

- **ëª¨ë“ˆí™”ëœ êµ¬ì„± ìš”ì†Œ**: ì²´ì¸, ì—ì´ì „íŠ¸, ë©”ëª¨ë¦¬ ë“± ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì»´í¬ë„ŒíŠ¸
- **ë‹¤ì–‘í•œ LLM ì§€ì›**: OpenAI, Anthropic, Hugging Face ë“±
- **ì™¸ë¶€ ë„êµ¬ ì—°ë™**: ì›¹ ê²€ìƒ‰, ë°ì´í„°ë² ì´ìŠ¤, API ë“±
- **ë©”ëª¨ë¦¬ ê´€ë¦¬**: ëŒ€í™” ê¸°ë¡ ë° ì»¨í…ìŠ¤íŠ¸ ìœ ì§€

## ğŸ—ï¸ LangChain í•µì‹¬ êµ¬ì„± ìš”ì†Œ

### 1. LLM (Large Language Model)

```python
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI

# ê¸°ë³¸ LLM
llm = OpenAI(temperature=0.7)

# ì±„íŒ… ëª¨ë¸
chat_model = ChatOpenAI(
    model_name="gpt-3.5-turbo",
    temperature=0.7
)
```

### 2. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿

```python
from langchain.prompts import PromptTemplate

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
template = """
ë‹¹ì‹ ì€ {role}ì…ë‹ˆë‹¤.
ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ {tone}ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

ì§ˆë¬¸: {question}
ë‹µë³€:
"""

prompt = PromptTemplate(
    input_variables=["role", "tone", "question"],
    template=template
)

# í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
formatted_prompt = prompt.format(
    role="AI ì „ë¬¸ê°€",
    tone="ì¹œê·¼í•˜ê²Œ",
    question="ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ëŠ” ì–´ë–»ê²Œ ë ê¹Œìš”?"
)
```

### 3. ì²´ì¸ (Chain)

```python
from langchain.chains import LLMChain

# LLM ì²´ì¸ ìƒì„±
chain = LLMChain(llm=llm, prompt=prompt)

# ì²´ì¸ ì‹¤í–‰
result = chain.run(
    role="AI ì „ë¬¸ê°€",
    tone="ì¹œê·¼í•˜ê²Œ",
    question="ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ëŠ” ì–´ë–»ê²Œ ë ê¹Œìš”?"
)
```

## ğŸ¤– AI ì—ì´ì „íŠ¸ ë§Œë“¤ê¸°

### 1. ê¸°ë³¸ ì—ì´ì „íŠ¸

```python
from langchain.agents import initialize_agent, Tool
from langchain.agents import AgentType
from langchain.llms import OpenAI

# ë„êµ¬ ì •ì˜
def search_tool(query: str) -> str:
    """ì›¹ ê²€ìƒ‰ ë„êµ¬"""
    # ì‹¤ì œ ê²€ìƒ‰ ë¡œì§ êµ¬í˜„
    return f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤."

def calculator_tool(expression: str) -> str:
    """ê³„ì‚°ê¸° ë„êµ¬"""
    try:
        result = eval(expression)
        return f"ê³„ì‚° ê²°ê³¼: {result}"
    except:
        return "ê³„ì‚°í•  ìˆ˜ ì—†ëŠ” ì‹ì…ë‹ˆë‹¤."

# ë„êµ¬ ë¦¬ìŠ¤íŠ¸
tools = [
    Tool(
        name="Search",
        func=search_tool,
        description="ì›¹ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤."
    ),
    Tool(
        name="Calculator",
        func=calculator_tool,
        description="ìˆ˜í•™ ê³„ì‚°ì„ í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤."
    )
]

# ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
agent = initialize_agent(
    tools=tools,
    llm=OpenAI(temperature=0),
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

# ì—ì´ì „íŠ¸ ì‹¤í–‰
result = agent.run("2024ë…„ ì¸ê³µì§€ëŠ¥ íŠ¸ë Œë“œë¥¼ ê²€ìƒ‰í•˜ê³ , ê·¸ ì¤‘ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ 3ê°€ì§€ë¥¼ ì„ ì •í•´ì£¼ì„¸ìš”.")
```

### 2. ê³ ê¸‰ ì—ì´ì „íŠ¸: ë©”ëª¨ë¦¬ ê¸°ëŠ¥

```python
from langchain.memory import ConversationBufferMemory
from langchain.agents import initialize_agent

# ë©”ëª¨ë¦¬ ì„¤ì •
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)

# ë©”ëª¨ë¦¬ê°€ ìˆëŠ” ì—ì´ì „íŠ¸
agent_with_memory = initialize_agent(
    tools=tools,
    llm=OpenAI(temperature=0),
    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
    memory=memory,
    verbose=True
)

# ëŒ€í™”í˜• ì—ì´ì „íŠ¸ ì‚¬ìš©
result1 = agent_with_memory.run("ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” AIì— ê´€ì‹¬ì´ ìˆìŠµë‹ˆë‹¤.")
result2 = agent_with_memory.run("ì•ì„œ ë§ì”€í•˜ì‹  AIì— ëŒ€í•´ ë” ìì„¸íˆ ì•Œë ¤ì£¼ì„¸ìš”.")
```

## ğŸ› ï¸ ì‹¤ì „ í”„ë¡œì íŠ¸: ê°œì¸ ë¹„ì„œ ì—ì´ì „íŠ¸

### 1. í”„ë¡œì íŠ¸ êµ¬ì¡°

```
personal_assistant/
â”œâ”€â”€ main.py
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ weather.py
â”‚   â”œâ”€â”€ calendar.py
â”‚   â””â”€â”€ email.py
â”œâ”€â”€ agents/
â”‚   â””â”€â”€ assistant_agent.py
â””â”€â”€ config.py
```

### 2. ë„êµ¬ êµ¬í˜„

```python
# tools/weather.py
import requests

def get_weather(city: str) -> str:
    """ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    # ì‹¤ì œ API í˜¸ì¶œ (ì˜ˆì‹œ)
    api_key = "your_api_key"
    url = f"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}"
    
    try:
        response = requests.get(url)
        data = response.json()
        return f"{city}ì˜ í˜„ì¬ ë‚ ì”¨: {data['weather'][0]['description']}, ì˜¨ë„: {data['main']['temp']}Â°C"
    except:
        return f"{city}ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# tools/calendar.py
from datetime import datetime, timedelta

def get_schedule(date: str = None) -> str:
    """ì¼ì •ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    if date is None:
        date = datetime.now().strftime("%Y-%m-%d")
    
    # ì‹¤ì œ ì¼ì • ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ (ì˜ˆì‹œ)
    schedule = [
        {"time": "09:00", "title": "íŒ€ ë¯¸íŒ…"},
        {"time": "14:00", "title": "í”„ë¡œì íŠ¸ ë¦¬ë·°"},
        {"time": "16:00", "title": "ê³ ê° ìƒë‹´"}
    ]
    
    result = f"{date} ì¼ì •:\n"
    for item in schedule:
        result += f"- {item['time']}: {item['title']}\n"
    
    return result

def add_schedule(time: str, title: str, date: str = None) -> str:
    """ì¼ì •ì„ ì¶”ê°€í•©ë‹ˆë‹¤."""
    if date is None:
        date = datetime.now().strftime("%Y-%m-%d")
    
    # ì‹¤ì œ ì¼ì • ì¶”ê°€ ë¡œì§
    return f"{date} {time}ì— '{title}' ì¼ì •ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤."

# tools/email.py
def send_email(to: str, subject: str, body: str) -> str:
    """ì´ë©”ì¼ì„ ë°œì†¡í•©ë‹ˆë‹¤."""
    # ì‹¤ì œ ì´ë©”ì¼ ë°œì†¡ ë¡œì§
    return f"{to}ì—ê²Œ '{subject}' ì œëª©ìœ¼ë¡œ ì´ë©”ì¼ì„ ë°œì†¡í–ˆìŠµë‹ˆë‹¤."
```

### 3. ì—ì´ì „íŠ¸ êµ¬í˜„

```python
# agents/assistant_agent.py
from langchain.agents import initialize_agent, Tool
from langchain.agents import AgentType
from langchain.llms import OpenAI
from langchain.memory import ConversationBufferMemory
from tools.weather import get_weather
from tools.calendar import get_schedule, add_schedule
from tools.email import send_email

class PersonalAssistantAgent:
    def __init__(self):
        self.setup_tools()
        self.setup_memory()
        self.setup_agent()
    
    def setup_tools(self):
        """ë„êµ¬ ì„¤ì •"""
        self.tools = [
            Tool(
                name="Weather",
                func=get_weather,
                description="íŠ¹ì • ë„ì‹œì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. ì…ë ¥: ë„ì‹œëª…"
            ),
            Tool(
                name="Schedule",
                func=get_schedule,
                description="ì¼ì •ì„ ì¡°íšŒí•©ë‹ˆë‹¤. ì…ë ¥: ë‚ ì§œ (YYYY-MM-DD í˜•ì‹, ì„ íƒì‚¬í•­)"
            ),
            Tool(
                name="AddSchedule",
                func=add_schedule,
                description="ì¼ì •ì„ ì¶”ê°€í•©ë‹ˆë‹¤. ì…ë ¥: ì‹œê°„, ì œëª©, ë‚ ì§œ (ì„ íƒì‚¬í•­)"
            ),
            Tool(
                name="Email",
                func=send_email,
                description="ì´ë©”ì¼ì„ ë°œì†¡í•©ë‹ˆë‹¤. ì…ë ¥: ìˆ˜ì‹ ì, ì œëª©, ë‚´ìš©"
            )
        ]
    
    def setup_memory(self):
        """ë©”ëª¨ë¦¬ ì„¤ì •"""
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
    
    def setup_agent(self):
        """ì—ì´ì „íŠ¸ ì„¤ì •"""
        self.agent = initialize_agent(
            tools=self.tools,
            llm=OpenAI(temperature=0.7),
            agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
            memory=self.memory,
            verbose=True
        )
    
    def chat(self, message: str) -> str:
        """ì‚¬ìš©ìì™€ ëŒ€í™”"""
        return self.agent.run(message)

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    assistant = PersonalAssistantAgent()
    
    # ëŒ€í™” ì˜ˆì‹œ
    print(assistant.chat("ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ê°€ ì–´ë•Œìš”?"))
    print(assistant.chat("ì˜¤ëŠ˜ ì¼ì •ì´ ë­ê°€ ìˆë‚˜ìš”?"))
    print(assistant.chat("ë‚´ì¼ ì˜¤í›„ 2ì‹œì— 'í”„ë¡œì íŠ¸ ë¯¸íŒ…' ì¼ì •ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”."))
```

## ğŸ”§ ê³ ê¸‰ ê¸°ëŠ¥

### 1. ì»¤ìŠ¤í…€ ë„êµ¬ í´ë˜ìŠ¤

```python
from langchain.tools import BaseTool
from typing import Optional, Type
from pydantic import BaseModel, Field

class WeatherInput(BaseModel):
    city: str = Field(description="ë‚ ì”¨ë¥¼ ì¡°íšŒí•  ë„ì‹œëª…")

class WeatherTool(BaseTool):
    name = "weather_tool"
    description = "íŠ¹ì • ë„ì‹œì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."
    args_schema: Type[BaseModel] = WeatherInput
    
    def _run(self, city: str) -> str:
        return get_weather(city)
    
    def _arun(self, city: str) -> str:
        raise NotImplementedError("ë¹„ë™ê¸° ì‹¤í–‰ì€ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# ì»¤ìŠ¤í…€ ë„êµ¬ ì‚¬ìš©
custom_tools = [WeatherTool()]
```

### 2. ì—ì´ì „íŠ¸ ì²´ì¸ ì—°ê²°

```python
from langchain.chains import SimpleSequentialChain
from langchain.chains import LLMChain

# ì²« ë²ˆì§¸ ì²´ì¸: ì§ˆë¬¸ ë¶„ì„
analysis_prompt = PromptTemplate(
    input_variables=["question"],
    template="ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  í•„ìš”í•œ ë„êµ¬ë¥¼ ê²°ì •í•˜ì„¸ìš”: {question}"
)
analysis_chain = LLMChain(llm=llm, prompt=analysis_prompt)

# ë‘ ë²ˆì§¸ ì²´ì¸: ë‹µë³€ ìƒì„±
answer_prompt = PromptTemplate(
    input_variables=["analysis", "question"],
    template="ë¶„ì„ ê²°ê³¼: {analysis}\nì›ë˜ ì§ˆë¬¸: {question}\në‹µë³€:"
)
answer_chain = LLMChain(llm=llm, prompt=answer_prompt)

# ì²´ì¸ ì—°ê²°
overall_chain = SimpleSequentialChain(
    chains=[analysis_chain, answer_chain],
    verbose=True
)

result = overall_chain.run("ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë–¤ê°€ìš”?")
```

### 3. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ

```python
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

# ìŠ¤íŠ¸ë¦¬ë° LLM
streaming_llm = OpenAI(
    streaming=True,
    callbacks=[StreamingStdOutCallbackHandler()],
    temperature=0.7
)

# ìŠ¤íŠ¸ë¦¬ë° ì—ì´ì „íŠ¸
streaming_agent = initialize_agent(
    tools=tools,
    llm=streaming_llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

# ì‹¤ì‹œê°„ ì‘ë‹µ
result = streaming_agent.run("ë³µì¡í•œ ìˆ˜í•™ ë¬¸ì œë¥¼ í’€ì–´ì£¼ì„¸ìš”.")
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### 1. ìºì‹± í™œìš©

```python
from langchain.cache import InMemoryCache
from langchain.globals import set_llm_cache

# ë©”ëª¨ë¦¬ ìºì‹œ ì„¤ì •
set_llm_cache(InMemoryCache())

# ë™ì¼í•œ ì§ˆë¬¸ì— ëŒ€í•´ ìºì‹œëœ ê²°ê³¼ ë°˜í™˜
result1 = agent.run("ì¸ê³µì§€ëŠ¥ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?")
result2 = agent.run("ì¸ê³µì§€ëŠ¥ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?")  # ìºì‹œì—ì„œ ë°˜í™˜
```

### 2. ë¹„ë™ê¸° ì²˜ë¦¬

```python
import asyncio
from langchain.agents import initialize_agent

async def async_agent_run(agent, query):
    """ë¹„ë™ê¸° ì—ì´ì „íŠ¸ ì‹¤í–‰"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, agent.run, query)

# ì—¬ëŸ¬ ì§ˆë¬¸ ë™ì‹œ ì²˜ë¦¬
queries = [
    "ì˜¤ëŠ˜ ë‚ ì”¨ëŠ”?",
    "ë‚´ì¼ ì¼ì •ì€?",
    "ì´ë²ˆ ì£¼ ê³„íšì€?"
]

async def process_queries():
    tasks = [async_agent_run(agent, query) for query in queries]
    results = await asyncio.gather(*tasks)
    return results

# ì‹¤í–‰
results = asyncio.run(process_queries())
```

## ğŸ¯ ì‹¤ì œ í™œìš© ì‚¬ë¡€

### 1. ê³ ê° ì„œë¹„ìŠ¤ ë´‡

```python
class CustomerServiceBot:
    def __init__(self):
        self.tools = [
            Tool(
                name="OrderLookup",
                func=self.lookup_order,
                description="ì£¼ë¬¸ ë²ˆí˜¸ë¡œ ì£¼ë¬¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."
            ),
            Tool(
                name="RefundProcess",
                func=self.process_refund,
                description="í™˜ë¶ˆ ì²˜ë¦¬ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤."
            ),
            Tool(
                name="ProductInfo",
                func=self.get_product_info,
                description="ì œí’ˆ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."
            )
        ]
        
        self.agent = initialize_agent(
            tools=self.tools,
            llm=OpenAI(temperature=0.3),
            agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
            verbose=True
        )
    
    def handle_customer_query(self, query: str) -> str:
        return self.agent.run(query)
```

### 2. ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸

```python
class DataAnalysisAgent:
    def __init__(self):
        self.tools = [
            Tool(
                name="LoadData",
                func=self.load_data,
                description="ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."
            ),
            Tool(
                name="AnalyzeData",
                func=self.analyze_data,
                description="ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."
            ),
            Tool(
                name="CreateVisualization",
                func=self.create_visualization,
                description="ì‹œê°í™”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
            )
        ]
        
        self.agent = initialize_agent(
            tools=self.tools,
            llm=OpenAI(temperature=0.1),
            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
            verbose=True
        )
    
    def analyze(self, request: str) -> str:
        return self.agent.run(request)
```

## ğŸš€ ë°°í¬ ë° ìš´ì˜

### 1. FastAPIì™€ ì—°ë™

```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class ChatRequest(BaseModel):
    message: str

class ChatResponse(BaseModel):
    response: str

# ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤
assistant = PersonalAssistantAgent()

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    response = assistant.chat(request.message)
    return ChatResponse(response=response)

@app.get("/health")
async def health_check():
    return {"status": "healthy"}
```

### 2. ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

```python
import logging
from langchain.callbacks import BaseCallbackHandler

class LoggingCallbackHandler(BaseCallbackHandler):
    def on_agent_action(self, action, **kwargs):
        logging.info(f"Agent Action: {action}")
    
    def on_agent_finish(self, finish, **kwargs):
        logging.info(f"Agent Finish: {finish}")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)

# ì—ì´ì „íŠ¸ì— ì½œë°± ì¶”ê°€
agent = initialize_agent(
    tools=tools,
    llm=OpenAI(temperature=0),
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    callbacks=[LoggingCallbackHandler()],
    verbose=True
)
```

## ğŸ¯ ë§ˆë¬´ë¦¬

LangChainì„ í™œìš©í•˜ë©´ ë³µì¡í•œ AI ì—ì´ì „íŠ¸ë¥¼ ì‰½ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

### í•µì‹¬ í¬ì¸íŠ¸

1. **ëª¨ë“ˆí™”**: ë„êµ¬, ì²´ì¸, ë©”ëª¨ë¦¬ ë“±ì„ ë…ë¦½ì ìœ¼ë¡œ êµ¬ì„±
2. **í™•ì¥ì„±**: ìƒˆë¡œìš´ ë„êµ¬ì™€ ê¸°ëŠ¥ì„ ì‰½ê²Œ ì¶”ê°€
3. **ìœ ì—°ì„±**: ë‹¤ì–‘í•œ LLMê³¼ ë„êµ¬ ì¡°í•© ê°€ëŠ¥
4. **ì‹¤ìš©ì„±**: ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì œ í•´ê²°ì— í™œìš© ê°€ëŠ¥

### ë‹¤ìŒ ë‹¨ê³„

- **LangGraph**: ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬
- **LangServe**: ì—ì´ì „íŠ¸ API ì„œë²„ êµ¬ì¶•
- **LangSmith**: ì—ì´ì „íŠ¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

LangChainìœ¼ë¡œ ë”ìš± ì§€ëŠ¥ì ì´ê³  ìœ ìš©í•œ AI ì—ì´ì „íŠ¸ë¥¼ ë§Œë“¤ì–´ë³´ì„¸ìš”!

---

**ì°¸ê³  ìë£Œ:**
- [LangChain ê³µì‹ ë¬¸ì„œ](https://python.langchain.com/)
- [LangChain GitHub](https://github.com/langchain-ai/langchain)
- [LangChain ì˜ˆì œ ëª¨ìŒ](https://github.com/langchain-ai/langchain/tree/master/templates)

*ì´ ê¸€ì´ ë„ì›€ì´ ë˜ì…¨ë‹¤ë©´ ëŒ“ê¸€ë¡œ í”¼ë“œë°±ì„ ë‚¨ê²¨ì£¼ì„¸ìš”! ğŸš€*
